{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, TypedDict, Annotated, Optional, Type, Union\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.callbacks import CallbackManagerForToolRun\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "_ = load_dotenv()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCallLog(TypedDict):\n",
    "    \"\"\"\n",
    "    A TypedDict representing a log entry for a tool call.\n",
    "\n",
    "    Attributes:\n",
    "        timestamp (str): The timestamp of when the tool call was made.\n",
    "        tool_call_id (str): The unique identifier for the tool call.\n",
    "        name (str): The name of the tool that was called.\n",
    "        args (Any): The arguments passed to the tool.\n",
    "        content (str): The content or result of the tool call.\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp: str\n",
    "    tool_call_id: str\n",
    "    name: str\n",
    "    args: Any\n",
    "    content: str\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"\n",
    "    A TypedDict representing the state of an agent.\n",
    "\n",
    "    Attributes:\n",
    "        messages (Annotated[List[AnyMessage], operator.add]): A list of messages\n",
    "            representing the conversation history. The operator.add annotation\n",
    "            indicates that new messages should be appended to this list.\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    A class representing an agent that processes requests and executes tools based on\n",
    "    language model responses.\n",
    "\n",
    "    Attributes:\n",
    "        model (BaseLanguageModel): The language model used for processing.\n",
    "        tools (Dict[str, BaseTool]): A dictionary of available tools.\n",
    "        checkpointer (Any): Manages and persists the agent's state.\n",
    "        system_prompt (str): The system instructions for the agent.\n",
    "        workflow (StateGraph): The compiled workflow for the agent's processing.\n",
    "        log_tools (bool): Whether to log tool calls.\n",
    "        log_path (Path): Path to save tool call logs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: BaseLanguageModel,\n",
    "        tools: List[BaseTool],\n",
    "        checkpointer: Any = None,\n",
    "        system_prompt: str = \"\",\n",
    "        log_tools: bool = True,\n",
    "        log_dir: Optional[str] = \"logs\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the Agent.\n",
    "\n",
    "        Args:\n",
    "            model (BaseLanguageModel): The language model to use.\n",
    "            tools (List[BaseTool]): A list of available tools.\n",
    "            checkpointer (Any, optional): State persistence manager. Defaults to None.\n",
    "            system_prompt (str, optional): System instructions. Defaults to \"\".\n",
    "            log_tools (bool, optional): Whether to log tool calls. Defaults to True.\n",
    "            log_dir (str, optional): Directory to save logs. Defaults to 'logs'.\n",
    "        \"\"\"\n",
    "        self.system_prompt = system_prompt\n",
    "        self.log_tools = log_tools\n",
    "\n",
    "        if self.log_tools:\n",
    "            self.log_path = Path(log_dir or \"logs\")\n",
    "            self.log_path.mkdir(exist_ok=True)\n",
    "\n",
    "        # Define the agent workflow\n",
    "        workflow = StateGraph(AgentState)\n",
    "        workflow.add_node(\"process\", self.process_request)\n",
    "        workflow.add_node(\"execute\", self.execute_tools)\n",
    "        workflow.add_conditional_edges(\n",
    "            \"process\", self.has_tool_calls, {True: \"execute\", False: END}\n",
    "        )\n",
    "        workflow.add_edge(\"execute\", \"process\")\n",
    "        workflow.set_entry_point(\"process\")\n",
    "\n",
    "        self.workflow = workflow.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def process_request(self, state: AgentState) -> Dict[str, List[AnyMessage]]:\n",
    "        \"\"\"\n",
    "        Process the request using the language model.\n",
    "\n",
    "        Args:\n",
    "            state (AgentState): The current state of the agent.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[AnyMessage]]: A dictionary containing the model's response.\n",
    "        \"\"\"\n",
    "        messages = state[\"messages\"]\n",
    "        if self.system_prompt:\n",
    "            messages = [SystemMessage(content=self.system_prompt)] + messages\n",
    "        response = self.model.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    def has_tool_calls(self, state: AgentState) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the response contains any tool calls.\n",
    "\n",
    "        Args:\n",
    "            state (AgentState): The current state of the agent.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if tool calls exist, False otherwise.\n",
    "        \"\"\"\n",
    "        response = state[\"messages\"][-1]\n",
    "        return len(response.tool_calls) > 0\n",
    "\n",
    "    def execute_tools(self, state: AgentState) -> Dict[str, List[ToolMessage]]:\n",
    "        \"\"\"\n",
    "        Execute tool calls from the model's response.\n",
    "\n",
    "        Args:\n",
    "            state (AgentState): The current state of the agent.\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, List[ToolMessage]]: A dictionary containing tool execution results.\n",
    "        \"\"\"\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "        results = []\n",
    "\n",
    "        for call in tool_calls:\n",
    "            print(f\"Executing tool: {call}\")\n",
    "            if call[\"name\"] not in self.tools:\n",
    "                print(\"\\n....invalid tool....\")\n",
    "                result = \"invalid tool, please retry\"\n",
    "            else:\n",
    "                result = self.tools[call[\"name\"]].invoke(call[\"args\"])\n",
    "\n",
    "            results.append(\n",
    "                ToolMessage(\n",
    "                    tool_call_id=call[\"id\"],\n",
    "                    name=call[\"name\"],\n",
    "                    args=call[\"args\"],\n",
    "                    content=str(result),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self._save_tool_calls(results)\n",
    "        print(\"Returning to model processing!\")\n",
    "\n",
    "        return {\"messages\": results}\n",
    "\n",
    "    def _save_tool_calls(self, tool_calls: List[ToolMessage]) -> None:\n",
    "        \"\"\"\n",
    "        Save tool calls to a JSON file with timestamp-based naming.\n",
    "\n",
    "        Args:\n",
    "            tool_calls (List[ToolMessage]): List of tool calls to save.\n",
    "        \"\"\"\n",
    "        if not self.log_tools:\n",
    "            return\n",
    "\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = self.log_path / f\"tool_calls_{timestamp}.json\"\n",
    "\n",
    "        logs: List[ToolCallLog] = []\n",
    "        for call in tool_calls:\n",
    "            log_entry = {\n",
    "                \"tool_call_id\": call.tool_call_id,\n",
    "                \"name\": call.name,\n",
    "                \"args\": call.args,\n",
    "                \"content\": call.content,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "            logs.append(log_entry)\n",
    "\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(logs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = DuckDuckGoSearchRun(\n",
    "    name=\"web_search\",\n",
    "    description=\"Search the web for current information. Input should be a search query string.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplicationInput(BaseModel):\n",
    "    \"\"\"Input schema for multiplication operation.\"\"\"\n",
    "\n",
    "    x: float = Field(..., description=\"First number to multiply\")\n",
    "    y: float = Field(..., description=\"Second number to multiply\")\n",
    "    round_to: int = Field(2, description=\"Number of decimal places to round to\")\n",
    "\n",
    "\n",
    "class MultiplicationTool(BaseTool):\n",
    "    \"\"\"Tool that multiplies two numbers together.\"\"\"\n",
    "\n",
    "    name: str = \"multiplication\"\n",
    "    description: str = \"Multiplies two numbers together. Input should be two numbers (x and y and round_to).\"\n",
    "    args_schema: Type[BaseModel] = MultiplicationInput\n",
    "\n",
    "    def _run(\n",
    "        self,\n",
    "        x: float,\n",
    "        y: float,\n",
    "        round_to: int = 2,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> Dict:\n",
    "        \"\"\"Multiply two numbers together.\n",
    "\n",
    "        Args:\n",
    "            x (float): First number\n",
    "            y (float): Second number\n",
    "            round_to (int): Number of decimal places to round to\n",
    "            run_manager (Optional[CallbackManagerForToolRun]): Callback manager\n",
    "\n",
    "        Returns:\n",
    "            Dict: Contains result and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = round(x * y, round_to)\n",
    "            return {\n",
    "                \"result\": result,\n",
    "                \"metadata\": {\n",
    "                    \"operation\": \"multiplication\",\n",
    "                    \"status\": \"completed\",\n",
    "                },\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"error\": str(e),\n",
    "                \"metadata\": {\n",
    "                    \"operation\": \"multiplication\",\n",
    "                    \"status\": \"failed\",\n",
    "                },\n",
    "            }\n",
    "\n",
    "    async def _arun(\n",
    "        self,\n",
    "        x: float,\n",
    "        y: float,\n",
    "        round_to: int = 2,\n",
    "        run_manager: Optional[CallbackManagerForToolRun] = None,\n",
    "    ) -> Dict:\n",
    "        \"\"\"Async version that calls the sync version.\"\"\"\n",
    "        return self._run(x, y, round_to)\n",
    "\n",
    "\n",
    "math_tool = MultiplicationTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a smart AI assistant.\"\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "model = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0, top_p=0.95)\n",
    "agent = Agent(\n",
    "    model,\n",
    "    tools=[search_tool, math_tool],\n",
    "    log_tools=True,\n",
    "    log_dir=\"aihub_logs\",\n",
    "    system_prompt=system_prompt,\n",
    "    checkpointer=checkpointer,\n",
    ")\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "Image(agent.workflow.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"Multiply the month and date of today?\"\n",
    "messages = [HumanMessage(content=content)]\n",
    "\n",
    "for event in agent.workflow.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v, \"\\n\")\n",
    "        print(\"--------------------------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
